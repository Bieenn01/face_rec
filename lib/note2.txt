
import 'dart:io';
import 'dart:ui';
import 'package:firebase_core/firebase_core.dart';
import 'package:flutter/cupertino.dart';
import 'package:flutter/foundation.dart';
import 'package:flutter/material.dart';
import 'package:camera/camera.dart';
import 'package:flutter/services.dart';
import 'package:google_mlkit_face_detection/google_mlkit_face_detection.dart';
import 'package:image/image.dart' as img;
import 'package:realtime_face_recognition/ML/Recognition.dart';

import 'ML/Recognition.dart';
import 'ML/Recognition.dart';
import 'ML/Recognition.dart';
import 'ML/Recognition.dart';
import 'ML/Recognizer.dart';

late List<CameraDescription> cameras;

Future<void> main() async {
  WidgetsFlutterBinding.ensureInitialized();
  cameras = await availableCameras();
  await Firebase.initializeApp();
  runApp(MyApp());
}

class MyApp extends StatelessWidget {
  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      home: MyHomePage(),
    );
  }
}

class MyHomePage extends StatefulWidget {
  @override
  _MyHomePageState createState() => _MyHomePageState();
}

class _MyHomePageState extends State<MyHomePage> {
  late CameraController controller;
  bool isBusy = false;
  late Size size;
  late CameraDescription description = cameras[1];
  CameraLensDirection camDirec = CameraLensDirection.front;
  late List<Recognition> recognitions = [];

  late FaceDetector detector;
  bool register = false;

  late Recognizer recognizer;

  @override
  void initState() {
    super.initState();
    initializeCamera();
    detector = FaceDetector(options: 
      FaceDetectorOptions(performanceMode: FaceDetectorMode.fast),
    );
    recognizer = Recognizer();
  }

  @override
  void dispose() {
    controller.dispose();
    detector.close();
    super.dispose();
  }

  void initializeCamera() async {
    controller = CameraController(description, ResolutionPreset.high);
    await controller.initialize().then((_) {
      if (!mounted) return;
      controller.startImageStream((CameraImage image) {
        if (!isBusy) {
          isBusy = true;
          frame = image;
          processCameraImage(image);
        }
      });
    });
  }

  dynamic _scanResults;
  late CameraImage frame;
  processCameraImage(CameraImage image) async {
    InputImage inputImage = getInputImage(image);
    List<Face> faces = await detector.processImage(inputImage);
    for (Face face in faces){
      print("Face location "+face.boundingBox.toString());
    }

    performFaceRecognition(faces);
    setState(() {
      // _scanResults = recognitions;
      isBusy = false;
    });
  }

  img.Image? image;
  // TODO perform Face Recognition
  void performFaceRecognition(List<Face> faces) async {
    recognitions.clear();
  
    //TODO convert CameraImage to Image and rotate it so that our frame will be in a portrait
    img.Image? image = await convertBGRA8888ToImage(frame!);
    image =img.copyRotate(image!, angle: camDirec == CameraLensDirection.front?270:90);
  
    for (Face face in faces) {
      Rect faceRect = face.boundingBox;
      //TODO crop face
      img.Image croppedFace = img.copyCrop(image!, x:faceRect.left.toInt(),y:faceRect.top.toInt(),width:faceRect.width.toInt(),height:faceRect.height.toInt());
  
      //TODO pass cropped face to face recognition model
      Recognition recognition = recognizer.recognize(croppedFace, face.boundingBox);
      recognitions.add(recognition);
  
      //TODO show face registration dialogue
      if(register){
        showFaceRegistrationDialogue(croppedFace, recognition);
        register = false;
      }  

    }      
    setState(() {
      isBusy = false;
      // _scanResults = recognitions;
    });
  }

  TextEditingController textEditingController = TextEditingController();
  showFaceRegistrationDialogue(img.Image croppedFace, Recognition recognition){
    showDialog(
      context: context,
      builder: (ctx) => AlertDialog(
        title: const Text("Face Registration",textAlign: TextAlign.center),alignment: Alignment.center,
        content: SizedBox(
          height: 340,
          child: Column(
            crossAxisAlignment: CrossAxisAlignment.center,
            children: [
              const SizedBox(height: 20,),
              Image.memory(Uint8List.fromList(img.encodeBmp(croppedFace!)),width: 200,height: 200,),
              SizedBox(
                width: 200,
                child: TextField(
                    controller: textEditingController,
                    decoration: const InputDecoration( fillColor: Colors.white, filled: true,hintText: "Enter Name")
                ),
              ),
              const SizedBox(height: 10,),
              ElevatedButton(
                  onPressed: () {
                    recognizer.registerFace(textEditingController.text, recognition.embeddings);
                    textEditingController.text = "";
                    Navigator.pop(context);
                    ScaffoldMessenger.of(context).showSnackBar(const SnackBar(
                      content: Text("Face Registered"),
                    ));
                  },style: ElevatedButton.styleFrom(backgroundColor: Colors.blue,minimumSize: const Size(200,40)),
                  child: const Text("Register"))
            ],
          ),
        ),contentPadding: EdgeInsets.zero,
      ),
    );
  }


  

  InputImage getInputImage(CameraImage image) {
    final camera =
    camDirec == CameraLensDirection.front ? cameras[1] : cameras[0];
    final int imageRotation =
        camera.sensorOrientation! + _rotationIntToImageRotation(0);
    final InputImageRotation rotation = InputImageRotation.values[
        imageRotation ~/ 90]; 

    return InputImage.fromBytes(
      bytes: _concatenatePlanes(image.planes),
      metadata: InputImageMetadata(
        size: Size(image.width.toDouble(), image.height.toDouble()),
        rotation: rotation,
        format: InputImageFormat.yuv420,
        bytesPerRow: imageRotation.bitLength,

      ),
    );
  }

    // TODO method to convert CameraImage to Image
Future<img.Image?> convertBGRA8888ToImage(CameraImage cameraImage) async {
  final width = cameraImage.width;
  final height = cameraImage.height;

  if (cameraImage.format.group != ImageFormatGroup.yuv420) {
    throw Exception('Unsupported image format: ${cameraImage.format}');
  }
  
  // Concatenate all bytes from the planes into a single Uint8List
  Uint8List bytes = Uint8List(cameraImage.planes.fold(0, (prev, plane) => prev + plane.bytes.length));
  int offset = 0;
  for (int i = 0; i < cameraImage.planes.length; i++) {
    bytes.setRange(offset, offset + cameraImage.planes[i].bytes.length, cameraImage.planes[i].bytes);
    offset += cameraImage.planes[i].bytes.length;
  }

  // Create an img.Image from the concatenated bytes
  final image = img.Image.fromBytes(width: width, height: height, bytes: bytes.buffer);

  return image;
}

  Uint8List _concatenatePlanes(List<Plane> planes) {
    final WriteBuffer allBytes = WriteBuffer();
    planes.forEach((plane) => allBytes.putUint8List(plane.bytes));
    return allBytes.done().buffer.asUint8List();
  }

  int _rotationIntToImageRotation(int rotation) =>
      <int>[0, 90, 180, 270][rotation];

  @override
  Widget build(BuildContext context) {
    size = MediaQuery.of(context).size;

    return SafeArea(
      child: Scaffold(
        backgroundColor: Colors.black,
        body: Stack(
          children: [
            Positioned.fill(
              child: (controller.value.isInitialized)
                  ? AspectRatio(
                      aspectRatio: controller.value.aspectRatio,
                      child: CameraPreview(controller),
                    )
                  : Center(child: CircularProgressIndicator()),
            ),
            Positioned(
              top: 0.0,
              left: 0.0,
              width: size.width,
              height: size.height,
              child: buildResult(),
            ),
            Positioned(
              bottom: 16.0,
              left: 16.0,
              right: 16.0,
              child: Row(
                mainAxisAlignment: MainAxisAlignment.spaceBetween,
                children: [
                  IconButton(
                    icon: Icon(Icons.flip_camera_ios),
                    onPressed: _toggleCameraDirection,
                    color: Colors.white,
                  ),
                  IconButton(
                    icon: Icon(Icons.face),
                    onPressed: () {
                      setState(() {
                        register = true;
                      });
                    },
                    color: Colors.white,
                  ),
                ],
              ),
            ),
          ],
        ),
      ),
    );
  }

    Widget buildResult() {
    if (_scanResults == null ||
        controller == null ||
        !controller.value.isInitialized) {
      return const Center(child: Text('Camera is not initialized'));
    }
    final Size imageSize = Size(
      controller.value.previewSize!.height,
      controller.value.previewSize!.width,
    );
    CustomPainter painter = FaceDetectorPainter(imageSize, _scanResults, camDirec);
    return CustomPaint(
      painter: painter,
    );
  }

  void _toggleCameraDirection() async {
    if (camDirec == CameraLensDirection.back) {
      camDirec = CameraLensDirection.front;
      description = cameras[1];
    } else {
      camDirec = CameraLensDirection.back;
      description = cameras[0];
    }
    await controller.stopImageStream();
    setState(() {
      controller;
    });

    initializeCamera();
  }

}

class FaceDetectorPainter extends CustomPainter {
  FaceDetectorPainter(this.absoluteImageSize, this.faces, this.camDire2);

  final Size absoluteImageSize;
  final List<Recognition> faces;
  CameraLensDirection camDire2;

  @override
  void paint(Canvas canvas, Size size) {
    final double scaleX = size.width / absoluteImageSize.width;
    final double scaleY = size.height / absoluteImageSize.height;

    final Paint paint = Paint()
      ..style = PaintingStyle.stroke
      ..strokeWidth = 2.0
      ..color = Colors.indigoAccent;

    for (Recognition face in faces) {
      canvas.drawRect(
        Rect.fromLTRB(
          camDire2 == CameraLensDirection.front
              ? (absoluteImageSize.width - face.location.right) * scaleX
              : face.location.left * scaleX,
          face.location.top * scaleY,
          camDire2 == CameraLensDirection.front
              ? (absoluteImageSize.width - face.location.left) * scaleX
              : face.location.right * scaleX,
          face.location.bottom * scaleY,
        ),
        paint,
      );

      TextSpan span = TextSpan(
          style: const TextStyle(color: Colors.white, fontSize: 20),
          text: "${face.name}  ${face.distance.toStringAsFixed(2)}");
      TextPainter tp = TextPainter(
          text: span,
          textAlign: TextAlign.left,
          textDirection: TextDirection.ltr);
      tp.layout();
      tp.paint(canvas, Offset(face.location.left*scaleX, face.location.top*scaleY));
    }

  }

  @override
  bool shouldRepaint(FaceDetectorPainter oldDelegate) {
    return true;
  }
}
